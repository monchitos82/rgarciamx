<!doctype html>
<html lang="en" color-scheme="light dark">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="./assets/style.css">

    <title>mon's blog ğŸ‘¾</title>
</head>

<body>
    <div id="content">
        <ul class="menu-bar">
            <li class="menu-item" id="posts">
                <a class="dropdown-btn" href="#" title="Posts">
                    Posts
                </a>
                <div class="dropdown-content">
                    <a class="dropdown-item" href="./posts/2026.html">2026</a>
                    <a class="dropdown-item" href="./posts/2025.html">2025</a>
                    <a class="dropdown-item" href="./posts/2024.html">2024</a>
                </div>
            </li>
        </ul>
        <br />
    </div>
    <h3>Uploading Python jobs to flink through the JAR API (11/25)</h3>
    <p>Let me start this post by making some leveling in expectations. This post is not focused on how to build jobs for
        <em>Flink</em> or what is the right strategy to make these stream tasks. It isn&rsquo;t either a bragging one. I
        just figured out this information is not available anywhere that I searched for.</p>
    <p>I have stated before that I am terrible at <em>Java</em>. I remember once a manager jokingly dismissed my work
        because I delivered a <em>PHP</em> solution rather than a <em>war</em> file because I could not write
        <em>Java</em>. He wasn&rsquo;t wrong. And to this day, I still have a hard time writing good <em>Java</em> code.
        So when I wanted to do some <em>Flink</em> work, I was happy when I found that it supports <em>Python</em>. But
        the support is far from perfect, and well, <em>Python</em> has its own flaws. Anyway, it took me some hours to
        get my job running right because I chose the <em>latest</em> build of my container and the driver is not very
        gentle giving feedback when something goes wrong. A lot went wrong.</p>
    <p>My job is simple:</p>
    <p>It queries <em>PostgreSQL</em> and performs an aggregation (batch), then sinks the aggregated data into
        <em>MongoDB</em>. Nothing more, nothing less. I know I don&rsquo;t make use of <em>Flink&rsquo;s</em> full
        potential by not even streaming data, but I have not much to produce for this scenario.</p>
    <pre>
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                             
  â”‚  PostgreSQL  â”‚                                                             
  â”‚   Database   â”‚                                                             
  â”‚              â”‚                                                             
  â”‚ simpleserviceâ”‚                                                             
  â”‚   requests   â”‚                                                             
  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                             
         â”‚                                                                      
         â”‚ JDBC Connector                                                      
         â”‚ (Read full table)                                                   
         â”‚                                                                      
         â–¼                                                                      
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            
  â”‚              FLINK TABLE ENVIRONMENT (Batch Mode)            â”‚            
  â”‚                                                              â”‚            
  â”‚  Source Table: request_logs                                  â”‚            
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            
  â”‚  â”‚ id            INT                                      â”‚  â”‚            
  â”‚  â”‚ ...           STRING                                   â”‚  â”‚                  
  â”‚  â”‚ timestamp     TIMESTAMP_LTZ(3)                         â”‚  â”‚            
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            
  â”‚                          â”‚                                   â”‚            
  â”‚                          â”‚ WHERE timestamp >= CURRENT - 1hr  â”‚            
  â”‚                          â–¼                                   â”‚            
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            
  â”‚  â”‚          AGGREGATION (GROUP BY something)              â”‚  â”‚            
  â”‚  â”‚                                                        â”‚  â”‚            
  â”‚  â”‚  â€¢ COUNT(*) as request_count                           â”‚  â”‚            
  â”‚  â”‚                                                        â”‚  â”‚            
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            
  â”‚                          â”‚                                   â”‚            
  â”‚                          â–¼                                   â”‚            
  â”‚  Sink Table: agg_requests                                    â”‚            
  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚            
  â”‚  â”‚ endpoint       STRING (PRIMARY KEY)                    â”‚  â”‚            
  â”‚  â”‚ request_count  BIGINT                                  â”‚  â”‚            
  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚            
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            
                             â”‚                                                 
                             â”‚ MongoDB Connector                               
                             â”‚ (Upsert by endpoint)                            
                             â”‚                                                 
                             â–¼                                                 
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                        
                  â”‚     MongoDB      â”‚                                        
                  â”‚                  â”‚                                                                            
                  â”‚  agg_requests    â”‚                                        
                  â”‚   collection     â”‚                                        
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   
</pre>

    <p>I could get this working in v.1.19 by running the <em>Flink CLI</em>, but this requires using the container
        rather than doing this remotely, so if I wanted to trigger this from something like an <em>Airflow DAG</em> it
        would just not work. I had to find a way to get this working. The solution I found (and where I made great use
        of <em>Claude</em>) was wrapping things in a <em>JAR</em>. But this required learning <em>Maven</em>, doing some
        <em>Java</em> work and trying to get things to run. Well, I found a way to get the <em>POM</em> ready and put
        all my dependencies in the libs directory, but even then all I could trigger were exceptions and my container
        died.</p>
    <p>I had to do some introspection into what my job was doing wrong and if that&rsquo;s fixed in newer versions, and
        even if there is a proposal for an <code>artifacts</code> endpoint, <em>Python</em> support is limited and my
        job could not run.</p>
    <p>After some back and forth, I tried wrapping the <em>Python</em> code in a <em>JAR</em> without using
        <em>Maven</em>, but it still failed:</p>
    <pre>
# Basically wrote the MANIFEST to point to the python dir and wrap the .py file, then pack and send
jar -cfm python-app.jar META-INF/MANIFEST.MF python/
</pre>

    <p>This produced nothing useful but exceptions. Then I had a Bingo! moment. My initial exceptions were around the
        driver not being able to find my script, because somehow, the driver assumes the file is in a <code>/tmp</code>
        location and it copies it before invoking <code>Flink</code>, so what if there is no need to copy?</p>
    <pre><code>
2025-11-28 22:31:54,061 WARN  org.apache.flink.client.python.PythonEnvUtils                [] - Create symbol link from /tmp/pyflink/4cab4606-4d40-423c-9da2-110f4d7858b9/ff3fe4a6-f89a-4fec-a849-5ececc23caee/flink-job-2466975472410535843.py to /tmp/flink-job-2466975472410535843.py failed and copy instead.
ï¿½java.nio.file.NoSuchFileException: /tmp/pyflink/4cab4606-4d40-423c-9da2-110f4d7858b9/ff3fe4a6-f89a-4fec-a849-5ececc23caee/flink-job-2466975472410535843.py
        at sun.nio.fs.UnixException.translateToIOException(Unknown Source) ~[?:?]
        at sun.nio.fs.UnixException.rethrowAsIOException(Unknown Source) ~[?:?]
        at sun.nio.fs.UnixException.rethrowAsIOException(Unknown Source) ~[?:?]
        at sun.nio.fs.UnixFileSystemProvider.createSymbolicLink(Unknown Source) ~[?:?]
        at java.nio.file.Files.createSymbolicLink(Unknown Source) ~[?:?]
ï¿½       at org.apache.flink.client.python.PythonEnvUtils.createSymbolicLink(PythonEnvUtils.java:240) ~[flink-python-1.19.3.jar:1.19.3]
        at org.apache.flink.client.python.PythonEnvUtils.addToPythonPath(PythonEnvUtils.java:294) ~[flink-python-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.client.python.PythonEnvUtils.preparePythonEnvironment(PythonEnvUtils.java:226) ~[flink-python-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.client.python.PythonEnvUtils.launchPy4jPythonClient(PythonEnvUtils.java:487) ~[flink-python-1.19.3.jar:1.19.3]
        at org.apache.flink.client.python.PythonDriver.main(PythonDriver.java:92) ~[flink-python-1.19.3.jar:1.19.3]
ï¿½       at com.example.PythonJobLauncher.main(PythonJobLauncher.java:33) ~[de9b8c19-aa32-4320-9852-2a6ed7f3abae_flink-python-job-1.0-SNAPSHOT.jar:?]
        at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
        at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) ~[?:?]
        at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) ~[?:?]
        at java.lang.reflect.Method.invoke(Unknown Source) ~[?:?]
        at org.apache.flink.client.program.PackagedProgram.callMainMethod(PackagedProgram.java:355) ~[flink-dist-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.client.program.PackagedProgram.invokeInteractiveModeForExecution(PackagedProgram.java:222) ~[flink-dist-1.19.3.jar:1.19.3]
        at org.apache.flink.client.ClientUtils.executeProgram(ClientUtils.java:108) ~[flink-dist-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.client.deployment.application.DetachedApplicationRunner.tryExecuteJobs(DetachedApplicationRunner.java:84) ~[flink-dist-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.client.deployment.application.DetachedApplicationRunner.run(DetachedApplicationRunner.java:70) ~[flink-dist-1.19.3.jar:1.19.3]
ï¿½       at org.apache.flink.runtime.webmonitor.handlers.JarRunHandler.lambda$handleRequest$0(JarRunHandler.java:108) ~[flink-dist-1.19.3.jar:1.19.3]
        at java.util.concurrent.CompletableFuture$AsyncSupply.run(Unknown Source) [?:?]
        at java.lang.Thread.run(Unknown Source) [?:?]
</code></pre>

    <p>Well, this is where the <em>LLM</em> saved my ass. I decided to stream the code into a location using the
        <em>JAR</em> rather than copying it extracting it and moving it, but I didn&rsquo;t know how to do it in Java.
        This is totally a hack and requires awareness on the stream size and what is actually tolerable for the process
        (don&rsquo;t you dare to try loading a whole package in it!). For my case, however, this worked great, and I
        could right away trigger jobs using a <em>CURL</em> call to the <em>API</em>:</p>
    <pre>
# Send my JAR
curl -s -X POST http://localhost:8081/jars/upload -F "jarfile=@flink-python-job-1.0-SNAPSHOT.jar"


# List my JAR ID
curl http://localhost:8081/jars | jq

# Run my Python Job
curl -s -X POST "http://localhost:8081/jars/<JAR ID>_flink-python-job-1.0-SNAPSHOT.jar/run" -H "Content-Type: application/json"
</pre>

    <p>So if you find yourself in the same pickle, here&rsquo;s the class to get this whole mess fixed. Long term fix:
        Improve my <em>Java</em> knowledge.</p>
    <pre><code>
package com.example;

import org.apache.flink.client.python.PythonDriver;
import java.io.InputStream;
import java.io.OutputStream;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.nio.file.StandardCopyOption;

public class PythonJobLauncher {
    public static void main(String[] args) {
        try {
            // Extract Python script from JAR resources
            InputStream pythonScript = PythonJobLauncher.class
                .getResourceAsStream("/main.py");

            if (pythonScript == null) {
                throw new RuntimeException("main.py not found in JAR resources");
            }

            // Write to a predictable location that won't be moved
            // Use the working directory instead of /tmp
            Path pythonFile = Paths.get("job.py").toAbsolutePath();

            System.out.println("Extracting Python script to: " + pythonFile);

            // Write the file
            try (OutputStream out = Files.newOutputStream(pythonFile)) {
                byte[] buffer = new byte[8192];
                int bytesRead;
                while ((bytesRead = pythonScript.read(buffer)) != -1) {
                    out.write(buffer, 0, bytesRead);
                }
            }

            System.out.println("Python script written successfully");
            System.out.println("File exists: " + Files.exists(pythonFile));
            System.out.println("File size: " + Files.size(pythonFile));

            // Build arguments for Python driver
            String[] pythonArgs = new String[] {
                "-py", pythonFile.toString()
            };

            System.out.println("Calling PythonDriver with: -py " + pythonFile);

            // Launch Python job
            PythonDriver.main(pythonArgs);

            System.out.println("PythonDriver completed");

        } catch (Throwable e) {
            System.err.println("Failed to launch Python job: " + e.getMessage());
            e.printStackTrace();
            throw new RuntimeException("Python job failed", e);
        }
    }
}
</code></pre>
</body>

</html>