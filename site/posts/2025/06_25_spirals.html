<!doctype html>
<html lang="en" color-scheme="light dark">

<head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <link rel="stylesheet" href="./assets/style.css">

    <title>mon's blog ðŸ‘¾</title>
</head>

<body>
    <div id="content">
        <ul class="menu-bar">
            <li class="menu-item" id="posts">
                <a class="dropdown-btn" href="#" title="Posts">
                    Posts
                </a>
                <div class="dropdown-content">
                    <a class="dropdown-item" href="./posts/2026.html">2026</a>
                    <a class="dropdown-item" href="./posts/2025.html">2025</a>
                    <a class="dropdown-item" href="./posts/2024.html">2024</a>
                </div>
            </li>
        </ul>
        <br />
    </div>
    <h3>Spirals (06/25)</h3>
    <p>I wish I had something interesting to say here, especially something unrelated to <em>LLMs</em>. Unfortunately, I
        am doing some prep work. One would think that <em>LLMs</em> would be very helpful with preparations by giving us
        problems, guidance and feedback. I thought the same. The results are catastrophic.</p>
    <p>I get good explanations and good problems from my conversations with <em>ChatGPT</em> (and <em>Claude</em> too),
        but when I try to get insight into things and even solutions, I am the kind of person who tries to take an extra
        step, that extra step is what any congruent person would do: validate for correctness. Well, the results are
        demoralizing.</p>
    <p>I wish I could write down all my findings and prompts, but I would resume everything with one image:</p>
    <pre>
0 0 0 0 0 0 0
0 X X X X X X
0 X 0 0 0 0 X
0 X 0 X X 0 X
0 X 0 0 X 0 X
0 X X X X 0 X
0 0 0 0 0 0 X
</pre>

    <p>This is a &ldquo;simple&rdquo; problem. You get a matrix of size N (<code>NxN</code>). Then your program:</p>
    <ul>
        <li>Finds the center of the matrix</li>
        <li>Fills the matrix with a spiral that emerges from the center and replaces <code>0</code> by <code>X</code>
        </li>
        <li>Solves the problem using an O(nÂ²) time complexity</li>
        <li>Bonus points if the spiral direction can be switched</li>
    </ul>
    <p>Well, I got these beautiful responses:</p>
    <pre>
# Claude 4 and GPT 4o
X X X X X X X
X 0 0 0 0 0 X
X 0 X X X 0 X
X 0 X X X 0 X
X 0 X X X 0 X
X 0 0 0 0 0 X
X X X X X X X

# Claude 4
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X

# GPT 4o
X X X X X X X
X 0 0 0 0 0 X
X 0 X X X 0 X
X 0 X 0 X 0 X
X 0 X X X 0 X
X 0 0 0 0 0 X
X X X X X X X

# Claude 4
0 0 0 0 0 0 0
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
X X X X X X X
</pre>

    <p>In all outputs the models were confident they solved the problem correctly. But I am not here to throw shit at
        the <em>LLMs</em>. I want to document how these models become actually useful&hellip; Well, the results greatly
        changed when I provided the solution. Then my own inefficiencies were corrected.</p>
    <p>I started by presenting a problem and the expected results. Then I tried to tighten it a little bit by giving
        constraints, expected input and expected output. Then I provided a hint of what the code could be (provided a
        non-working solution). Once the model started working on the code I started asking about inefficiencies. Here
        the workflow broke because as I have mentioned before, models tend to stick to the context so if you provide a
        non-working example, it will try to improve that example without understanding it. So I provided a working
        example with a plethora of inefficiencies. At this point the modelsâ€™ focus shifted from trying to fix my code to
        trying to make it less wasteful; it removed expensive lookups, it added guardrails (not needed, but tried), it
        reduced the code complexity. I presented both models with challenges on their decisions and both provided
        insight. They were not &ldquo;smart&rdquo; enough to steer away from the <em>&ldquo;You are totally
            right!&rdquo;</em> answer, but they were actually trying to solve what they could.</p>
    <p><em>LLMs</em> can be helpful and should be considered helpful. They cannot show you the way, that&rsquo;s all on
        you. But they can help you look back and figure out where you could have planned better. So no vibe coding, no
        intellect replacement, no hallucinated solutions, simply what they do with any other document: Process,
        simplify, explain.</p>
    <p><sub><em>(2025-08-12) Update: I tried this again in GPT-5, Opus, LeChat, R1, Qwen Code, Perplexity, Gemini and
                CoPilot, all, <strong>no exceptions</strong>, kept failing miserably.</em></sub></p>
    <p><a href="../../snippets/spirals.html" target="_blank" title="Read snippet">
            snippet with my solution
        </a></p>
</body>

</html>